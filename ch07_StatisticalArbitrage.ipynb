{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Raw Cell Format",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hideki-Iwaki-TUS/Seminer2025/blob/Mei/ch07_StatisticalArbitrage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# パッケージのインポート"
      ],
      "metadata": {
        "id": "do2vmsDed-3Q"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYTbl334yWii"
      },
      "source": [
        "#numpy:数値計算 pandas:データ操作　matplotlib.pyplot:グラフ描画　をインポート。\n",
        "#時系列分析のJohansen共和分検定とベクトル誤差修正モデル（VECM）のためにstatsmodelsライブラリの特定のモジュールをインポート\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
        "from statsmodels.tsa.api import VECM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "これらは、後続のコードで時系列データの分析とモデル構築を行うために必要なツールです。\n",
        "\n",
        "**import pandas as pd**\n",
        "\n",
        "このコード は、Pythonでデータ操作や分析によく使われる pandas ライブラリをインポートしています。pd という短いエイリアスを付けることで、コード内で pandas の機能を使う際に pd.function_name のように簡潔に記述できるようになります。\n",
        "\n",
        "**import matplotlib.pyplot as plt**\n",
        "\n",
        "このコードは、Pythonでグラフを作成したりデータを可視化するためによく使われる matplotlib.pyplot モジュールをインポートしています。plt という短いエイリアスを付けることで、コード内で matplotlib.pyplot の機能を使う際に plt.function_name のように簡潔に記述できるようになります。\n",
        "\n",
        "\n",
        "**from statsmodels.tsa.vector_ar.vecm import coint_johansen**\n",
        "\n",
        "\n",
        "これは、共和分過程かどうかを統計的に検定する「Johansen共和分検定」を実行するための coint_johansen 関数をインポートしている。\n",
        "\n",
        "**from statsmodels.tsa.api import VECM**\n",
        "\n",
        "VECMは、パラメーターを推定する。\n"
      ],
      "metadata": {
        "id": "kFErgBdRkHbH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# パラメータの設定"
      ],
      "metadata": {
        "id": "YBByL7aTeB5U"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qL_1wMstyWil"
      },
      "source": [
        "Sigma = np.array([[1,0,0],[0,1,0],[0,0,1]])\n",
        "\n",
        "a_1 = np.array([0.1,0.2,0.3]) # alpha_1\n",
        "a_2 = np.array([0.5,-0.3,-0.3])\n",
        "b_1 = np.array([1,-0.5,-0.5]) # beta_1\n",
        "b_2 = np.array([-0.2,0.5,-0.2])\n",
        "\n",
        "A = np.stack([a_1,a_2],axis = 1) # alpha_2\n",
        "B = np.stack([b_1,b_2]) # beta_2\n",
        "\n",
        "Pi_1 = np.dot(a_1.reshape(3,1),b_1.reshape(1,3))\n",
        "Pi_2 = np.dot(A,B)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "はい、このコードは時系列モデル、特にVECMのパラメータを定義しています。\n",
        "\n",
        "np.array は NumPy ライブラリの関数で、NumPy配列（ndarray）を作成するために使用されます。NumPy配列は、数値計算を効率的に行うための多次元配列オブジェクトです。\n",
        "\n",
        "\n",
        "Sigma: 誤差項の共分散行列を表す3x3の単位行列です。\n",
        "\n",
        "a_1, a_2: 「アルファ」ベクトルを表します。\n",
        "\n",
        "b_1, b_2: 「ベータ」ベクトルを表します。\n",
        "\n",
        "A, B: a_1とa_2をスタックして行列A（アルファ行列）を作成し、b_1とb_2をスタックして行列B（ベータ行列）を作成しています。\n",
        "\n",
        "axis=0（デフォルト）: 新しい軸を先頭（0番目）に追加して結合します。例えば、2つの1次元配列を axis=0 で結合すると、それぞれの1次元配列が行となり、2次元配列が作成されます。\n",
        "axis=1: 新しい軸を1番目に追加して結合します。例えば、2つの1次元配列を axis=1 で結合すると、それぞれの1次元配列が列となり、2次元配列が作成されます。\n",
        "\n",
        "Pi_1: a_1とb_1の外積として計算されます。これは、特定の共和分関係を持つ長期的な影響行列を示します。\n",
        "\n",
        "Pi_2: AとBの行列積として計算されます。これは、より高次の共和分ランクを持つ可能性のある別の共和分行列を表しています。\n",
        "これらのパラメータは、後続のシミュレーションやVECMの推定に使用されます。\n",
        "\n",
        "a_1 は np.array([0.1,0.2,0.3]) という1次元配列（形状は (3,)）です。要素が３つある１次元配列\n",
        "\n",
        "a_1.reshape(3,1) はこの1次元配列を 3行1列の2次元配列（列ベクトル） に変換します。つまり、[[0.1], [0.2], [0.3]] のようになります。\n",
        "\n",
        "\n",
        "同様に、b_1 は np.array([1,-0.5,-0.5]) という1次元配列（形状は (3,)）です。\n",
        "\n",
        "\n",
        "b_1.reshape(1,3) はこの1次元配列を 1行3列の2次元配列（行ベクトル） に変換します。つまり、[[1, -0.5, -0.5]] のようになります。\n",
        "\n",
        "reshape:配列の形状（次元）を変更するため"
      ],
      "metadata": {
        "id": "HIqNddm8qmOo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgdpyScpyWil"
      },
      "source": [
        "#乱数を発生させる\n",
        "np.random.seed(seed = 1)\n",
        "rand_nums = np.random.randn(20000,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "乱数を生成するための準備を行っている。\n",
        "\n",
        "\n",
        "**np.random.seed(seed = 1)**\n",
        "\n",
        "これはNumPyの乱数生成器のシードを設定しています。シード（初期値）を設定することで、コードを何回実行しても常に同じ乱数列が生成されるようになります。これにより、結果の再現性が保証されます。\n",
        "\n",
        "\n",
        "**rand_nums = np.random.randn(20000,3)**\n",
        "\n",
        "np.random.randn() は、標準正規分布（平均0、標準偏差1）に従う乱数を生成する関数です。\n",
        "(20000, 3) は、生成される配列の形状を指定しています。これは、20,000行、3列の2次元配列を意味します。つまり、3つの変数に対する正規分布に従うランダムなノイズや誤差を表すデータセットが作成されます。\n",
        "\n"
      ],
      "metadata": {
        "id": "CHiYheH8vkn8"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME9fmC16yWio"
      },
      "source": [
        "#S_??の初期化\n",
        "init = np.array([1,1,1])\n",
        "S_rw = init #ランダムウォーク\n",
        "S_ci1 = init　#ランク１の共和分過程\n",
        "S_ci2 = init　#ランク２の共和分過程"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "変数の初期値設定。\n",
        "\n",
        "**init = np.array([1,1,1])**\n",
        "\n",
        "これは init という名前の変数に、要素が [1, 1, 1] のNumPy配列を代入しています。この配列は、シミュレーションを開始する際の基準となる初期状態を表します。\n",
        "\n",
        "**S_rw = init**\n",
        "\n",
        "**S_ci1 = init**\n",
        "\n",
        "**S_ci2 = init**\n",
        "\n",
        "これらの行では、S_rw、S_ci1、S_ci2 という3つの変数を、先に定義した init 配列で初期化しています。これは、異なる種類の時系列モデル（例えば、ランダムウォークや共和分モデル）のシミュレーションを開始する際の共通の初期条件として、すべて [1, 1, 1] からスタートすることを示しています。\n"
      ],
      "metadata": {
        "id": "EtawnuH1w5am"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNOt6sVpyWiq"
      },
      "source": [
        "#時系列の生成\n",
        "for rand_num in rand_nums:\n",
        "    S_rw = np.vstack((S_rw,S_rw[len(S_rw)-1] + np.dot(rand_num,Sigma)))\n",
        "    S_ci1 = np.vstack((S_ci1,np.dot(Pi_1 + np.eye(3),S_ci1[len(S_ci1)-1])\n",
        "                       + np.dot(rand_num,Sigma)))\n",
        "    S_ci2 = np.vstack((S_ci2,np.dot(Pi_2 + np.eye(3),S_ci2[len(S_ci2)-1])\n",
        "                       + np.dot(rand_num,Sigma)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "事前に設定されたパラメータと乱数を使用して、3種類の時系列データをシミュレーションしています。\n",
        "\n",
        "**for rand_num in rand_nums**\n",
        "\n",
        "これは、乱数配列 rand_nums の各行（つまり各時点のランダムショック＝予測できない突然の変動や外乱を表す要素。ホワイトノイズ？）を順に処理するためのループです。\n",
        "\n",
        "各時系列 S_rw, S_ci1, S_ci2 の更新は、以下の論理に基づいて行われます。\n",
        "\n",
        "**S_rw = np.vstack((S_rw,S_rw[len(S_rw)-1] + np.dot(rand_num,Sigma)))**\n",
        "\n",
        "これはランダムウォークをシミュレーションしています。次の時点の S_rw の値は、現在の S_rw の値に、乱数 rand_num と共分散行列 Sigma の積（つまりランダムなショック）を加えたものとして計算されます。\n",
        "np.vstack は、新しい行（計算された次の時点の値）を既存の S_rw 配列の下に垂直方向に結合して追加しています。\n",
        "\n",
        "S_rw[len(S_rw)-1]\n",
        "\n",
        "これは S_rw 配列の現在の長さを取得し、そこから1を引くことで、最後の要素のインデックスを指しています。つまり、現在の時系列の最後の時点の値を参照するために len が使用されています。\n",
        "\n",
        "\n",
        "**S_ci1 = np.vstack((S_ci1,np.dot(Pi_1 + np.eye(3),S_ci1[len(S_ci1)-1]) + np.dot(rand_num,Sigma)))**\n",
        "\n",
        "これは共和分ランク1の時系列をシミュレーションしています。np.eye(3)（3x3の単位行列）が加えられています。この部分は、前の状態と長期的な関係に基づいて決定される変動を表します。\n",
        "\n",
        "\n",
        "これに rand_num と Sigma から計算されるランダムなショックが加算され、S_ci1 が更新されます。\n",
        "\n",
        "\n",
        "**S_ci2 = np.vstack((S_ci2,np.dot(Pi_2 + np.eye(3),S_ci2[len(S_ci2)-1]) + np.dot(rand_num,Sigma)))**\n",
        "\n",
        "これは共和分ランク2の時系列をシミュレーションしています。基本的な構造は S_ci1 と同じですが、ここでは Pi_2 行列が使用されています。これにより、異なる共和分関係がモデル化されます。\n",
        "\n",
        "\n",
        "まとめると、このループはそれぞれの初期値から開始し、20,000ステップにわたってランダムウォークおよび共和分関係を持つ時系列データを生成しています。これにより、後のJohansen検定やVECMの推定で利用されるデータが作成されます。"
      ],
      "metadata": {
        "id": "liLvpYHzyJGa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Johansen検定"
      ],
      "metadata": {
        "id": "TCnfq7y9e8ZK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## $\\mathbf{S}_{\\textbf{RW}}$をテスト(共和分検定を)する"
      ],
      "metadata": {
        "id": "SgkaPcJkffvF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdQsyl5ZyWis"
      },
      "source": [
        "#ランダムウォークに対して共和分過程\n",
        "JohansenTestResult_rw = coint_johansen(S_rw,k_ar_diff=0,det_order=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**coint_johansen** は、複数の非定常な時系列変数間に長期的な安定した関係（共和分関係）が存在するかどうかを統計的に検定するための関数です。\n",
        "\n",
        "S_rw は、理論的には共和分関係がないと予想されます。\n",
        "\n",
        "\n",
        "**k_ar_diff=0**\n",
        "\n",
        "これは、階数の個数が０と指定。0は、VECMモデルにラグがないことを意味します。\n",
        "\n",
        "**det_order=-1**\n",
        "\n",
        "これは、共和分検定における決定論的トレンド成分（切片やトレンド項）の扱いを指定。\n",
        "\n",
        "-1 は、定数項もトレンド項もモデルに含まないことを意味します。定数項ｃをゼロに制約、つまり、モデルはデータが原点から始まることを仮定します。\n",
        "\n",
        "トレンド項（trend term）とは、時系列データに長期的に見られる持続的な上昇または下降の動き、つまり「トレンド」を表現するための数学的な要素のことです。時系列分析において、データが時間とともに一方向に変化する傾向を捉えるためにモデルに組み込まれます。\n",
        "\n",
        "\n",
        "この検定の結果は JohansenTestResult_rw に格納される"
      ],
      "metadata": {
        "id": "cRtziPxV0u10"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "出力\n"
      ],
      "metadata": {
        "id": "n8yrJZCS55ix"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mq-OE-w0yWit",
        "outputId": "436ce3c3-e4da-45f7-fc11-7c65334fb6be"
      },
      "source": [
        "print(JohansenTestResult_rw.lr1) # Trace statistic"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22.58036266  8.78820583  2.43645402]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lr1 は、ヨハンセン共和分検定における「トレース統計量（Trace statistic）」を指します。トレース統計量は、共和分関係の数（共和分ランク）を判断するために使われる統計量の一つです。\n",
        "\n",
        "具体的には、共和分ランクが0から最大数までであるという帰無仮説を順次検定するために使用されます。この値と、同時に出力される臨界値（critical values）を比較することで、共和分関係が存在するかどうか、そしてその数がいくつであるかを統計的に判断します。"
      ],
      "metadata": {
        "id": "CR2j7oTc6F7m"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8dfaeb8-dd4a-4d39-d692-5d3dbed2580f",
        "id": "cKSlM8d068bb"
      },
      "source": [
        "print(JohansenTestResult_rw.lr2) # Maximum eigenvalue statistic"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13.79215683  6.35175181  2.43645402]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lr2 は、ヨハンセン共和分検定における「最大固有値統計量（Maximum eigenvalue statistic）」を指します。最大固有値統計量も、トレース統計量と同様に共和分関係の数（共和分ランク）を判断するために使われる統計量の一つです。\n",
        "\n",
        "この統計量は、共和分ランクが r であるという帰無仮説を、共和分ランクが r+1 であるという対立仮説に対して検定するために使用されます。この値と、同時に出力される臨界値（critical values）を比較することで、共和分関係が存在するかどうか、そしてその数がいくつであるかを統計的に判断します。\n",
        "\n"
      ],
      "metadata": {
        "id": "ARpMOa-V6-_c"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqncefwdyWiu",
        "outputId": "db8f8b1b-4c28-43d2-92e9-41e79646517d"
      },
      "source": [
        "print(JohansenTestResult_rw.cvt) # Critical values (90%,95%,99%) of trace statistic"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[21.7781 24.2761 29.5147]\n",
            " [10.4741 12.3212 16.364 ]\n",
            " [ 2.9762  4.1296  6.9406]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiY2Kr_-yWit",
        "outputId": "e8dfaeb8-dd4a-4d39-d692-5d3dbed2580f"
      },
      "source": [
        "print(JohansenTestResult_rw.lr2) # Maximum eigenvalue statistic"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13.79215683  6.35175181  2.43645402]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znW559THyWiv",
        "outputId": "c6f48e8d-61a2-49dd-8f27-59fa510a6319"
      },
      "source": [
        "print(JohansenTestResult_rw.cvm) # Critical values (90%,95%,99%) of maximum eigenvalue statistic"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[15.7175 17.7961 22.2519]\n",
            " [ 9.4748 11.2246 15.0923]\n",
            " [ 2.9762  4.1296  6.9406]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## $\\mathbf{S}_{\\textbf{CI},1}$をテストする"
      ],
      "metadata": {
        "id": "3mMLrvY6fxLw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG5kZ6FbyWiv"
      },
      "source": [
        "JohansenTestResult_s1 = coint_johansen(S_ci1,k_ar_diff=0,det_order=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bloHkaYXyWiv",
        "outputId": "f39eba9c-723e-4312-ba8a-6e654e752227"
      },
      "source": [
        "print(JohansenTestResult_s1.lr1) # Trace statistic\n",
        "print(JohansenTestResult_s1.cvt) # Critical values (90%,95%,99%) of trace statistic\n",
        "print(JohansenTestResult_s1.lr2) # Maximum eigenvalue statistic\n",
        "print(JohansenTestResult_s1.cvm) # Critical values (90%,95%,99%) of maximum eigenvalue statistic"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.15097289e+04 1.42336157e+01 1.08408520e+00]\n",
            "[[21.7781 24.2761 29.5147]\n",
            " [10.4741 12.3212 16.364 ]\n",
            " [ 2.9762  4.1296  6.9406]]\n",
            "[1.14954952e+04 1.31495305e+01 1.08408520e+00]\n",
            "[[15.7175 17.7961 22.2519]\n",
            " [ 9.4748 11.2246 15.0923]\n",
            " [ 2.9762  4.1296  6.9406]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## $\\mathbf{S}_{\\textbf{CI,2}}$をテストする"
      ],
      "metadata": {
        "id": "qmIQwuhDgKsc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qdf6vU9ayWiw"
      },
      "source": [
        "JohansenTestResult_s2 = coint_johansen(S_ci2,k_ar_diff=0,det_order=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frG_hmIayWiw",
        "outputId": "a4bdd4c0-ff74-4617-a137-63df304f7157"
      },
      "source": [
        "print(JohansenTestResult_s2.lr1) # Trace statistic\n",
        "print(JohansenTestResult_s2.cvt) # Critical values (90%,95%,99%) of trace statistic\n",
        "print(JohansenTestResult_s2.lr2) # Maximum eigenvalue statistic\n",
        "print(JohansenTestResult_s2.cvm) # Critical values (90%,95%,99%) of maximum eigenvalue statistic"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3.24178966e+04 6.11019131e+03 2.57568342e+00]\n",
            "[[21.7781 24.2761 29.5147]\n",
            " [10.4741 12.3212 16.364 ]\n",
            " [ 2.9762  4.1296  6.9406]]\n",
            "[2.63077053e+04 6.10761563e+03 2.57568342e+00]\n",
            "[[15.7175 17.7961 22.2519]\n",
            " [ 9.4748 11.2246 15.0923]\n",
            " [ 2.9762  4.1296  6.9406]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# モデル・パラメータの推定"
      ],
      "metadata": {
        "id": "sU89CF4bgYj4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## $\\mathbf{S}_{\\textbf{CI},1}$のパラメータ推定"
      ],
      "metadata": {
        "id": "8VG6qZ5Lgg9Q"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA4jHD5ByWiw"
      },
      "source": [
        "model_s1 = VECM(S_ci1,k_ar_diff=0,coint_rank = 1, deterministic='na')\n",
        "res_s1 = model_s1.fit()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9C38DFmyWix",
        "outputId": "f79b88fe-4d41-4816-a729-0d58918913f2"
      },
      "source": [
        "print(res_s1.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Loading coefficients (alpha) for equation y1                 \n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "ec1            0.0998      0.003     32.514      0.000       0.094       0.106\n",
            "                 Loading coefficients (alpha) for equation y2                 \n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "ec1            0.2077      0.003     68.038      0.000       0.202       0.214\n",
            "                 Loading coefficients (alpha) for equation y3                 \n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "ec1            0.3019      0.003     98.418      0.000       0.296       0.308\n",
            "          Cointegration relations for loading-coefficients-column 1           \n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "beta.1         1.0000          0          0      0.000       1.000       1.000\n",
            "beta.2        -0.5000      0.000  -1849.489      0.000      -0.501      -0.499\n",
            "beta.3        -0.4997      0.000  -1218.700      0.000      -0.501      -0.499\n",
            "==============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxUvlKM8yWix",
        "outputId": "95292340-0817-4932-b6a2-424157b11c46"
      },
      "source": [
        "print(res_s1.alpha)\n",
        "print(res_s1.beta)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.09983864]\n",
            " [0.20767309]\n",
            " [0.30188794]]\n",
            "[[ 1.        ]\n",
            " [-0.50000816]\n",
            " [-0.49972569]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## $\\mathbf{S}_{\\textbf{CI},2}$のパラメータ\n",
        "\n",
        "\n",
        "*   リスト項目\n",
        "*   リスト項目\n",
        "\n"
      ],
      "metadata": {
        "id": "3pF8ZXoggz6B"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xknj9Ms4yWix",
        "outputId": "fa9bad07-cae7-45cf-8f0b-e8934f05af67"
      },
      "source": [
        "model_s2 = VECM(S_ci2,k_ar_diff=0,coint_rank = 2, deterministic='na')\n",
        "res_s2 = model_s2.fit()\n",
        "\n",
        "print(res_s2.alpha)\n",
        "print(res_s2.beta)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.00295261  0.19832263]\n",
            " [ 0.26430882 -0.25658122]\n",
            " [ 0.36024384 -0.29875471]]\n",
            "[[ 1.00000000e+00 -1.10297307e-16]\n",
            " [ 4.27951128e-17  1.00000000e+00]\n",
            " [-8.74973589e-01 -7.49993120e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gc4GF_16yWix",
        "outputId": "1dfe510d-246a-4df0-8cde-1c7d85203e61"
      },
      "source": [
        "print(np.dot(res_s2.alpha,res_s2.beta.transpose()))\n",
        "print(Pi_2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.00295261  0.19832263 -0.15132406]\n",
            " [ 0.26430882 -0.25658122 -0.03882909]\n",
            " [ 0.36024384 -0.29875471 -0.09113987]]\n",
            "[[ 0.    0.2  -0.15]\n",
            " [ 0.26 -0.25 -0.04]\n",
            " [ 0.36 -0.3  -0.09]]\n"
          ]
        }
      ]
    }
  ]
}